{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vggface_vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc6/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "fc7/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 2622)              10742334  \n",
      "_________________________________________________________________\n",
      "fc8/softmax (Activation)     (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "face_model = VGGFace(model='vgg16', \n",
    "                weights='vggface',\n",
    "                input_shape=(224,224,3)) \n",
    "face_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in face_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "\n",
    "person_count = 2\n",
    "\n",
    "last_layer = face_model.get_layer('pool5').output\n",
    "\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(1024, activation='relu', name='fc6')(x)\n",
    "x = Dense(1024, activation='relu', name='fc7')(x)\n",
    "out = Dense(person_count, activation='softmax', name='fc8')(x)\n",
    "\n",
    "custom_face = Model(face_model.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 5\n",
    "train_path = 'cam_face'\n",
    "eval_path = 'cam_eval_face'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 2 classes.\n",
      "Found 19 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        train_path,\n",
    "                        target_size=(224,224),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='sparse',\n",
    "                        color_mode='rgb')\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=eval_path,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/9 [==============================] - 24s 2s/step - loss: 0.6887 - accuracy: 0.5417 - val_loss: 0.6961 - val_accuracy: 0.5824\n",
      "Epoch 2/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.6836 - accuracy: 0.6383 - val_loss: 0.6777 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.6825 - accuracy: 0.7292 - val_loss: 0.6890 - val_accuracy: 0.7333\n",
      "Epoch 4/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.6804 - accuracy: 0.7872 - val_loss: 0.6626 - val_accuracy: 0.7889\n",
      "Epoch 5/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.6743 - accuracy: 0.9787 - val_loss: 0.6750 - val_accuracy: 0.8901\n",
      "Epoch 6/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.6669 - accuracy: 0.9375 - val_loss: 0.6654 - val_accuracy: 0.9667\n",
      "Epoch 7/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.6637 - accuracy: 0.9167 - val_loss: 0.6631 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.6604 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.9889\n",
      "Epoch 9/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.6577 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.6499 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.6497 - accuracy: 0.9787 - val_loss: 0.6514 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.6430 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.6483 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.6341 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.6317 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.6290 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "10/9 [==============================] - 17s 2s/step - loss: 0.6271 - accuracy: 1.0000 - val_loss: 0.6467 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.6212 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.6160 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.6194 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.6079 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.6045 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.6067 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.5916 - accuracy: 1.0000 - val_loss: 0.5931 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "10/9 [==============================] - 17s 2s/step - loss: 0.5886 - accuracy: 1.0000 - val_loss: 0.5976 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.5944 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.5866 - accuracy: 1.0000 - val_loss: 0.5853 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.5790 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.5759 - accuracy: 1.0000 - val_loss: 0.5713 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.5654 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.5708 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.5664 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.5606 - accuracy: 1.0000 - val_loss: 0.5460 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.5537 - accuracy: 1.0000 - val_loss: 0.5415 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.5534 - accuracy: 1.0000 - val_loss: 0.5699 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.5485 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.5381 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.5418 - accuracy: 1.0000 - val_loss: 0.5244 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.5302 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.5307 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.5186 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.5141 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.5128 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.5096 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.5129 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.5066 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.5002 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.4917 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.4903 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.4765 - accuracy: 1.0000 - val_loss: 0.4757 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.4852 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.4768 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "10/9 [==============================] - 17s 2s/step - loss: 0.4754 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.4668 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.4689 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.4608 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.4563 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.4509 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.4473 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.4281 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.4307 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.4341 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.4245 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.4173 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.4107 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.4089 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.4044 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.4050 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.3904 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.3902 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.3828 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.3773 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.3795 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.3690 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.3710 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.3593 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.3541 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.3576 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.3523 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.3460 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.3341 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.3357 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.3311 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.3331 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.3178 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.3229 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.3155 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.3006 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.3164 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/9 [==============================] - 22s 2s/step - loss: 0.2962 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.3023 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.2947 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.2946 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.2840 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.2865 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/9 [==============================] - 18s 2s/step - loss: 0.2712 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/9 [==============================] - 21s 2s/step - loss: 0.2854 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/9 [==============================] - 19s 2s/step - loss: 0.2652 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/9 [==============================] - 20s 2s/step - loss: 0.2738 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "custom_face.compile(loss='sparse_categorical_crossentropy',\n",
    "                         optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "history = custom_face.fit_generator(\n",
    "        train_generator,\n",
    "        validation_data=valid_generator,\n",
    "        steps_per_epoch=49/batch_size,\n",
    "        validation_steps=valid_generator.n,\n",
    "        epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> #note I could have over trained but sense there is not much data you need to train more</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_face.evaluate_generator(generator=valid_generator)\n",
    "        \n",
    "custom_face.save('h5 or xml files/my_face.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><strong>Face cam</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras_vggface import utils\n",
    "from keras_vggface.utils import preprocess_input\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_size = 224\n",
    "device_id = 0 #camera_device id \n",
    "\n",
    "model = load_model('h5 or xml files/my_face.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Trae': 0, 'Janessa': 1}\n"
     ]
    }
   ],
   "source": [
    "labels = dict(Trae=0,Janessa=1) \n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_classifier = cv2.CascadeClassifier('h5 or xml files/haarcascade_frontalface_default.xml')\n",
    "camera = cv2.VideoCapture(device_id)\n",
    "\n",
    "while camera.isOpened():\n",
    "    ok, cam_frame = camera.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    \n",
    "    gray_img=cv2.cvtColor(cam_frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces= cascade_classifier.detectMultiScale(gray_img, minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(cam_frame,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "        roi_color = cam_frame [y:y+h, x:x+w]\n",
    "        roi_color = cv2.cvtColor(roi_color, cv2.COLOR_BGR2RGB)\n",
    "        roi_color = cv2.resize(roi_color, (image_size, image_size))\n",
    "        image = roi_color.astype(np.float32, copy=False)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = preprocess_input(image, version=1) # or version=2\n",
    "        preds = model.predict(image)\n",
    "        predicted_class=np.argmax(preds,axis=1)\n",
    "         \n",
    "          \n",
    "\n",
    "        labels = (train_generator.class_indices)\n",
    "        labels = dict((v,k) for k,v in labels.items())\n",
    "        name = [labels[k] for k in predicted_class]\n",
    "        \n",
    "        cv2.putText(cam_frame,str(name), \n",
    "                    (x + 10, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                     (255,0,255), 2)\n",
    "        \n",
    "       \n",
    "    cv2.imshow('video image', cam_frame)\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27: # press 'ESC' to quit\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
